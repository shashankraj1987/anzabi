{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheets Usage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client Billing Descending -- Entire Sheet Not Used \n",
    "\n",
    "Fees By Worktype PIE Chart -- Entire Sheet not used  -- No Need to Process This \n",
    "\n",
    "Fees Summary by Dept and Fee Earner -- Entire Sheet Not Used\n",
    "\n",
    "============================================================\n",
    "\n",
    "Fee Breakdown by Dept and Fee earner -- Yes Except Textbox columns \n",
    "\n",
    "Fees Billed -- Yes Except TextBox Columns \n",
    "\n",
    "Matters Opened by FE -- Yes Except TextBox Columns \n",
    "\n",
    "Matter Sourece of Business Inc Matter Bills - Yes Except TextBox columns \n",
    "\n",
    "Payment Received Analysis  - Yes Except TextBox columns (Both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a Filename is not in this Dictionary, then it will not be Considered. \n",
    "skip_rows = {}\n",
    "\n",
    "skip_rows['Client Billing Descending'] = 0\n",
    "skip_rows[\"Fee Breakdown by Dept and Fee Earner\"] = 3\n",
    "skip_rows[\"Fee Summary by Dept and Fee Earner\"] = 3\n",
    "skip_rows[\"Fees Billed\"] = 3\n",
    "skip_rows[\"Matter Source of Business inc Matter Bills\"] = 0\n",
    "skip_rows[\"Matters Opened by FE\"] = 3\n",
    "skip_rows[\"Payment Received Analysis\"] = 3\n",
    "skip_rows[\"Total Hours by Fee Earner-With Billings\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(df):\n",
    "    \"\"\" \n",
    "    This will remove all the columns that contain the word Textbox in them. \n",
    "    This Function takes a DataFrame as in input and returns all the columns except TextBox. \n",
    "\n",
    "    \"\"\"\n",
    "    cols = df.columns\n",
    "    new_cols = []\n",
    "\n",
    "    for x in cols:\n",
    "        txt_chk = re.compile(r'Textbox')\n",
    "        if txt_chk.search(x)== None:\n",
    "            new_cols.append(x)\n",
    "        else: \n",
    "            continue\n",
    "    \n",
    "    return(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_files(loc, file_name,file_names_array, final_files_loc):\n",
    "    \"\"\"\n",
    "    loc = where these files are \n",
    "    file_name = current file name being processed \n",
    "    files names array = All the files that need to be concatenated \n",
    "\n",
    "    \"\"\"\n",
    "    df_final = pd.DataFrame()\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%m-%d-%y\") \n",
    "    print(f'Processing {file_name}')\n",
    "\n",
    "    for file in file_names_array:\n",
    "        dfc_file=pd.read_csv((loc+file), skiprows=get_rows(skip_rows,file))\n",
    "        dfc_file=dfc_file[remove_cols(dfc_file)]\n",
    "        \n",
    "        st_end_dates = get_start_enddate_from_Filename(file)\n",
    "        dfc_file[\"Process_Date\"] = st_end_dates[0]\n",
    "        #print(f'End Date from file is {st_end_dates[1]}')\n",
    "        # dfc_file[\"To_Date\"] = st_end_dates[1]\n",
    "        df_final = pd.concat([df_final,dfc_file],ignore_index=True)\n",
    "\n",
    "    # return df_final\n",
    "    final_file = final_files_loc+file_name+\"_\"+date+\"_.csv\"\n",
    "    df_final.to_csv(final_file,index=False)\n",
    "    print(f'Created {final_file}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_enddate_from_Filename(fname):\n",
    "    \"\"\"\n",
    "        Accepts a Filename that has fname_date.csv format. \n",
    "        It Extracts the From Date form the File and Returns the same. \n",
    "        These Are Datetime Objects.  \n",
    "\n",
    "        If the Filename has only start date, it will just return the same date for Both Start and End Date. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = re.compile(r'_\\d*')\n",
    "    match = pattern.findall(fname)\n",
    "    dt = match[0]\n",
    "    dt = dt.split(\"_\")[1]\n",
    "    start_date = pd.to_datetime(dt,format='%d%m%Y')\n",
    "    \n",
    "    return start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-03-01 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_start_enddate_from_Filename(\"Client Billing Descending_01032022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(dictnry, match):\n",
    "    \"\"\"\n",
    "        Takes a Dictionary and a filename as inputs and Returns how many rows need to be skipped for a filename. \n",
    "        Returns the Number of rows to skip, while creating a DataFrame.\n",
    "    \"\"\"\n",
    "    for val in dictnry.keys():\n",
    "        if re.match(val,match):\n",
    "            return (dictnry[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_file_names(files):\n",
    "\n",
    "    \"\"\" \n",
    "        This Function will Check a Given Location for all files and find the Unique File Names. \n",
    "        It Splits on the \"_\" as that is the current Naming Convention.\n",
    "        Also, it only find .csv files\n",
    "        Returns the Unique File Names.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_csvs = []\n",
    "    all_file_names = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            all_csvs.append(file)\n",
    "\n",
    "    for file in all_csvs:\n",
    "        fname = file.split(\"_\")[0]\n",
    "        all_file_names.append(fname)\n",
    "\n",
    "    all_file_names =  np.unique(all_file_names)\n",
    "    return all_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_processing(files_loc,files_list,final_files_loc):\n",
    "    print(\"Inside Final Processing\")\n",
    "    unique_files = get_unique_file_names(files_list) ## I need output of os.listdir\n",
    "    for each_file in unique_files:\n",
    "        print(f'\\nChecking [{each_file}]')\n",
    "        if each_file == \"Matter Source of Business inc Matter Bills (Bill Date)\":\n",
    "            each_file = \"Matter Source of Business inc Matter Bills\"\n",
    "        if each_file in skip_rows.keys():\n",
    "            pattern = re.compile(each_file)\n",
    "            each_file_arr = [file for file in files_list if len(pattern.findall(file))]\n",
    "            print(each_file_arr)\n",
    "            concat_files(files_loc,each_file,each_file_arr,final_files_loc)  \n",
    "        else: \n",
    "            print(f'Skipping Processing of [{each_file}]')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file_loc = \"/home/shashankraj/Documents/One_Drv_Anza/test/\"\n",
    "# final_xl_files_loc = \"/home/shashankraj/Documents/One_Drv_Anza/Final_Files/\"\n",
    "# data_files_list = os.listdir(data_file_loc)\n",
    "# data_files_list[:5]\n",
    "# final_processing(data_file_loc, data_files_list,final_xl_files_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fees Billed', '01032022.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"Fees Billed_01032022.csv\"\n",
    "word.split(\"_\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efeb6664015e98725bbb5b8b87814de131c81a1fd666b7e6d11b4ba6e020f0b0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
