{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_loc = \"/home/shashankraj/Documents/DATA/\"\n",
    "file_loc = r'C:\\Users\\shash\\OneDrive - Anza Services LLP\\DATA_Dump'\n",
    "unprocessed = file_loc+\"\\\\Unprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_rows = {}\n",
    "skip_rows['Client Billing Descending'] = 0\n",
    "skip_rows[\"Fee Breakdown by Dept and Fee Earner\"] = 3\n",
    "skip_rows[\"Fee Summary by Dept and Fee Earner\"] = 3\n",
    "skip_rows[\"Fees Billed\"] = 3\n",
    "skip_rows[\"Matter Source of Business inc Matter Bills\"] = 0\n",
    "skip_rows[\"Matters Opened by FE\"] = 3\n",
    "skip_rows[\"Payment Received Analysis\"] = 3\n",
    "skip_rows[\"Total Hours by Fee Earner-With Billings\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(df):\n",
    "    \"\"\" \n",
    "    This will remove all the columns that contain the word Textbox in them. \n",
    "    This Function takes a DataFrame as in input and returns all the columns except TextBox. \n",
    "\n",
    "    \"\"\"\n",
    "    cols = df.columns\n",
    "    new_cols = []\n",
    "\n",
    "    for x in cols:\n",
    "        txt_chk = re.compile(r'Textbox')\n",
    "        if txt_chk.search(x)== None:\n",
    "            new_cols.append(x)\n",
    "        else: \n",
    "            continue\n",
    "    \n",
    "    return(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(dictnry, match):\n",
    "    \"\"\"\n",
    "        Takes a Dictionary and a filename as inputs and Returns how many rows need to be skipped for a filename. \n",
    "        Returns the Number of rows to skip, while creating a DataFrame.\n",
    "    \"\"\"\n",
    "    for val in dictnry.keys():\n",
    "        if re.match(val,match):\n",
    "            return (dictnry[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_from_Filename(fname):\n",
    "    \"\"\"\n",
    "        Accepts a Filename that has fname_date.csv format. \n",
    "        It Extracts the From Date form the File and Returns the same. \n",
    "        These Are Datetime Objects.  \n",
    "\n",
    "        If the Filename has only start date, it will just return the same date for Both Start and End Date. \n",
    "\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'_\\d*')\n",
    "    match = pattern.findall(fname)\n",
    "    dt = match[0]\n",
    "    dt = dt.split(\"_\")[1]\n",
    "    file_date = pd.to_datetime(dt,format='%d%m%Y')\n",
    "    \n",
    "    return file_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_files(loc):\n",
    "    if os.name == 'posix':\n",
    "        os.system('clear')\n",
    "    else:\n",
    "        os.system('cls')\n",
    "    \n",
    "    process_files = {}\n",
    "    discard_files = {}\n",
    "    i=0\n",
    "    j=0\n",
    "    total = 0   \n",
    "    file_list = os.listdir(loc)\n",
    "\n",
    "    if os.path.exists(unprocessed):\n",
    "        print(f'\\n[Unprocessed] already Exists in [{file_loc}]\\n')\n",
    "    else: \n",
    "        os.mkdir(unprocessed)\n",
    "        print(f'\\nCreating Folder {unprocessed} in {file_loc}\\n')\n",
    "\n",
    "    ## Seggregating the Files.\n",
    "    discard_files['all_pie'] = [files for files in file_list if len(re.compile(r'[\\sa-zA-Z\\s]+Pie \\w+_\\d+.csv').findall(files))]\n",
    "    discard_files['all_xlsx'] = [files for files in file_list if files.endswith(\".xlsx\")]    \n",
    "\n",
    "    # Move the above files to Unprocessed Folder before moving ahead\n",
    "    for i in discard_files.keys():\n",
    "        for j in discard_files[i]:\n",
    "            shutil.move(file_loc+\"\\\\\"+j,unprocessed)\n",
    "            print(f'Moving File -- {j} to [{unprocessed}]')\n",
    "            total+=1\n",
    "\n",
    "    print(f'\\nMoved total {total} files to Unprocessed Folder')\n",
    "\n",
    "    process_files['client_billing'] = [files for files in file_list if len(re.compile(r'Client [a-zA-Z\\s]+_\\d+.csv').findall(files))]\n",
    "    process_files['fee_brkdn_dept_fe'] = [files for files in file_list if len(re.compile(r'Fee Breakdown [a-zA-Z\\s]+_\\d+.csv').findall(files))]\n",
    "    process_files['fee_summ_dept_fe'] = [files for files in file_list if len(re.compile(r'Fee Summary [a-zA-Z\\s]+_\\d+.csv').findall(files))]\n",
    "    process_files['fees_billed'] = [files for files in file_list if len(re.compile(r'Fees B[a-zA-Z\\s]+_\\d+.csv').findall(files))]\n",
    "    process_files['matter_src'] = [files for files in file_list if len(re.compile(r'Matter Source [a-zA-Z\\s()]+_\\d+.csv').findall(files))]\n",
    "    process_files['matter_opened'] = [files for files in file_list if len(re.compile(r'Matters Open[\\sa-zA-Z\\s()]+_\\d+.csv').findall(files))]\n",
    "    process_files['payment_rcv'] = [files for files in file_list if len(re.compile(r'Payment [\\sa-zA-Z\\s()]+_\\d+.csv').findall(files))]\n",
    "    process_files['tot_hrs_fe'] = [files for files in file_list if len(re.compile(r'([tT]otal[\\sa-z-A-Z\\s]*_\\d+.csv)').findall(files))]\n",
    "    \n",
    "    return process_files, total\n",
    "    #:TODO: \n",
    "    # Add these files individually to a database.\n",
    "    # Then concatenate these files and add them to staging database. \n",
    "    # No Need to move files in separate folders. Create a Dataframe in memory and perform operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_files(dict_list):\n",
    "    df_all_files = {}\n",
    "    tot_processed = 0\n",
    "    # If a Filename is not in this Dictionary, then it will not be Considered. \n",
    "    date = (datetime.now()).strftime(\"%m-%d-%y\")\n",
    "    for file_cat in dict_list.keys():\n",
    "        df_final = pd.DataFrame()\n",
    "        print(f'Processing Category {file_cat}')\n",
    "        print('*'*50)\n",
    "        for file in dict_list[file_cat]:\n",
    "            dict_fname = file.split(\"_\")[0]\n",
    "            dfc_file = pd.read_csv((file_loc+\"\\\\\"+file), skiprows=get_rows(skip_rows,file))\n",
    "            dfc_file = dfc_file[remove_cols(dfc_file)]\n",
    "            processing_date = get_date_from_Filename(file)\n",
    "            dfc_file[\"Date_Added\"] = processing_date\n",
    "            df_final = pd.concat([df_final,dfc_file],ignore_index=True)\n",
    "            \n",
    "            df_final.fillna(0)\n",
    "            df_final = df_final.replace(re.compile(r'Â£'),\"\").replace(re.compile(r','),\"\").replace(re.compile(r'\\('),\"\").replace(re.compile(r'\\)'),\"\")\n",
    "\n",
    "            for cols in df_final.columns:\n",
    "                try:\n",
    "                    df_final[cols].astype(float)\n",
    "                except:\n",
    "                    continue\n",
    "                else:\n",
    "                    df_final[cols] = df_final[cols].astype(float)\n",
    "        df_all_files[dict_fname] = df_final\n",
    "        #print(df_all_files.keys())\n",
    "    return df_all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Unprocessed] already Exists in [C:\\Users\\shash\\OneDrive - Anza Services LLP\\DATA_Dump]\n",
      "\n",
      "\n",
      "Moved total 0 files to Unprocessed Folder\n",
      "Processing Category client_billing\n",
      "**************************************************\n",
      "Processing Category fee_brkdn_dept_fe\n",
      "**************************************************\n",
      "Processing Category fee_summ_dept_fe\n",
      "**************************************************\n",
      "Processing Category fees_billed\n",
      "**************************************************\n",
      "Processing Category matter_src\n",
      "**************************************************\n",
      "Processing Category matter_opened\n",
      "**************************************************\n",
      "Processing Category payment_rcv\n",
      "**************************************************\n",
      "Processing Category tot_hrs_fe\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['Client Billing Descending', 'Fee Breakdown by Dept and Fee Earner', 'Fee Summary by Dept and Fee Earner', 'Fees Billed', 'Matter Source of Business inc Matter Bills (Bill Date)', 'Matters Opened by FE', 'Payment Received Analysis', 'Total Hours by Fee Earner-With Billings All'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_file_loc = categorize_files(file_loc)[0]\n",
    "dct = concat_files(all_file_loc)\n",
    "\n",
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feeref</th>\n",
       "      <th>month</th>\n",
       "      <th>SplitAmount</th>\n",
       "      <th>Date_Added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2022-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2022-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GB</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>1890.000</td>\n",
       "      <td>2022-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEH</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>1300.000</td>\n",
       "      <td>2022-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HY</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2022-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>RZ</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2022-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>SGK</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2022-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>SJ</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>6299.000</td>\n",
       "      <td>2022-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>TKC</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2022-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>TM</td>\n",
       "      <td>Mar 2022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2022-03-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feeref     month  SplitAmount Date_Added\n",
       "0       AB  Mar 2022        0.000 2022-03-01\n",
       "1       AL  Mar 2022        0.000 2022-03-01\n",
       "2       GB  Mar 2022     1890.000 2022-03-01\n",
       "3      HEH  Mar 2022     1300.000 2022-03-01\n",
       "4       HY  Mar 2022        0.000 2022-03-01\n",
       "..     ...       ...          ...        ...\n",
       "133     RZ  Mar 2022        0.000 2022-03-11\n",
       "134    SGK  Mar 2022        0.000 2022-03-11\n",
       "135     SJ  Mar 2022     6299.000 2022-03-11\n",
       "136    TKC  Mar 2022        0.000 2022-03-11\n",
       "137     TM  Mar 2022        0.000 2022-03-11\n",
       "\n",
       "[138 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct['Fees Billed']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
