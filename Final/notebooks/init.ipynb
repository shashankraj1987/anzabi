{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import organize_files as of\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'AnzaBI'\n",
    "db_user = 'db_Admin'\n",
    "db_password = 'password'\n",
    "db_host = '219.91.145.98'\n",
    "db_port = '5432'\n",
    "db_schema = '\"Bowling_Data\"'\n",
    "\n",
    "try:\n",
    "    engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db}',echo=True,future=True)\n",
    "except:\n",
    "    print(\"Unable to Create Database\")\n",
    "else:\n",
    "    print(\"COnnection Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    file_loc = r\"/home/shashankraj/Documents/DATA_Dump\"\n",
    "    log_file = file_loc+\"/\"+\"Logs\"\n",
    "    final_files = file_loc+\"/\"+\"Final_Df\"\n",
    "    backup = file_loc+\"/\"+\"Backup\"\n",
    "    #today = str(datetime.today().date())\n",
    "    trigger_file = file_loc+\"/file_trigger/\"+\"new_data_received.txt\"\n",
    "else:\n",
    "    file_loc=r\"D:\\Offline_Docs\\Anza\\DATA_Dump\"\n",
    "    log_file = file_loc+\"\\\\\"+\"Logs\"\n",
    "    final_files = file_loc+\"\\\\\"+\"Final_Df\"\n",
    "    backup = file_loc+\"\\\\\"+\"Backup\"\n",
    "    #today = str(datetime.today().date())\n",
    "    trigger_file = file_loc+\"\\\\file_trigger\\\\\"+\"new_data_received.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_ref = {\n",
    "    \"Client Billing Descending\":\"client_billing\",\"Fee Breakdown by Dept and Fee Earner\":\"fee_brkdn_dept_fe\",\"Fee Summary by Dept and Fee Earner\":\"fee_smry_dept_fe\",\n",
    "    \"Fees Billed\":\"fees_billed\",\"Matter Source of Business inc Matter Bills (Bill Date)\":\"mttr_src_ref\",\"Total Hours by Fee Earner-With Billings All\":\"tot_hrs_by_fe\",\n",
    "    \"Matters Opened by FE\":\"mtrs_by_fe\",\"Payment Received Analysis\":\"pmt_rcv_analysis\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = of.categorize_files(file_loc)\n",
    "all_files = of.concat_files(dict_list, file_loc, log_file)\n",
    "\n",
    "print(f'\\nLog Files are located at {log_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_files.keys():\n",
    "        all_files[file].columns = [cols.lower() for cols in all_files[file].columns]\n",
    "        fname = final_files+\"/\"+file+\".csv\"\n",
    "        if os.path.exists(fname):\n",
    "            print(f'{fname} already exists')\n",
    "            all_files[file].to_csv(final_files+\"/\"+file+\".csv\",header=False,mode=\"a\",index=False)\n",
    "        else:\n",
    "            print(f'Creating DF {fname}')\n",
    "            all_files[file].to_csv(final_files+\"/\"+file+\".csv\",mode=\"a\",index=False)\n",
    "        \n",
    "        # try: \n",
    "        #     all_files[file].to_sql(schema_ref[file],con=engine,if_exists='append',schema='Bowling_Data',index=None)\n",
    "        # except:\n",
    "        #     print(f\"***** Unable to write to Database for file [{file}]********* \")\n",
    "        # else:\n",
    "        #     print(f\"Putting all data in Postgresql Server for  [{file}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in os.listdir(final_files):\n",
    "    print(f'Processing {csv_file}')\n",
    "    if csv_file.endswith('.csv'):\n",
    "        tmp_df = pd.read_csv(final_files+\"/\"+csv_file)\n",
    "        tmp_df['date_added'] = pd.to_datetime(tmp_df['date_added'])\n",
    "        fname = backup+\"/\"+csv_file.split(\".\")[0]+\".parquet.gzip\"\n",
    "        print(f'Name is {fname}')\n",
    "        if os.path.exists(fname):\n",
    "            print(f'File already Exists, Removing')\n",
    "            os.remove(fname)\n",
    "        tmp_df.to_parquet(fname,compression = 'gzip')\n",
    "        print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing Cleanup\")\n",
    "\n",
    "[os.remove(file_loc+\"/Processed/\"+file) for file in os.listdir(file_loc+\"/Processed\")]\n",
    "[os.remove(file_loc+\"/Unprocessed/\"+file) for file in os.listdir(file_loc+\"/Unprocessed\")]\n",
    "[os.remove(file_loc+\"/file_trigger/\"+file) for file in os.listdir(file_loc+\"/file_trigger\")]\n",
    "[os.remove(file_loc+\"/\"+file) for file in os.listdir(file_loc) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cb = all_files['Client Billing Descending']\n",
    "# df_cb.head()\n",
    "# \"Cengiz Peri\" and pd.Timestamp(datetime.date(2022,3,2)) in df_cb[\"date_added\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(file_loc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
